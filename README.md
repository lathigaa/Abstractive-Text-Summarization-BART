# Abstractive-Text-Summarization-BART
Colab implementation of abstractive text summarization using BART Transformer on CNN/Daily Mail dataset

# Abstractive Text Summarization Using BART

## Overview
This Google Colab project implements abstractive text summarization using the BART transformer model. The model is fine-tuned on the CNN/Daily Mail dataset and evaluated using ROUGE scores.

## Dataset
- CNN/Daily Mail dataset

## Implementation
- Preprocessing: Tokenization, truncation, special tokens
- Model: BART (Bidirectional and Auto-Regressive Transformer)
- Fine-tuning: Using PyTorch & Hugging Face Transformers

## Results
- ROUGE-1: 44.5%
- ROUGE-2: 21.3%
- ROUGE-L: 41.7%

## Running the Notebook
Click https://colab.research.google.com/drive/1ZQFtnCGXQ4720VG7UsdjdQ3LKHe9klvK to open and run the Colab notebook.

## Contributors
Lathigaa
